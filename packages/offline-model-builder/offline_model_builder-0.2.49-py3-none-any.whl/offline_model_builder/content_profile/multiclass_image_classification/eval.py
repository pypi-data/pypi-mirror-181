from datetime import timedelta

from keras.utils import img_to_array
from tensorflow import lite
import cv2
import numpy as np
import os

from tensorflow import expand_dims
from config import config
# i.e if video of duration 30 seconds, saves 10 frame per second = 300 frames saved in total
from offline_model_builder.common.read_write_s3 import ConnectS3
from offline_model_builder.content_profile.multiclass_image_classification.config.config import TF_LITE_MODEL_LOCAL_PATH
from offline_model_builder.user_profile.constants import VISIONPLUS_DEV, TFLITE_MODEL_PATH

SAVING_FRAMES_PER_SECOND = 1


def format_timedelta(td):
    result = str(td)
    try:
        result, ms = result.split(".")
    except ValueError:
        return result + ".00".replace(":", "-")
    ms = int(ms)
    ms = round(ms / 1e4)
    return f"{result}.{ms:02}".replace(":", "-")


def get_saving_frames(cap, saving_fps):
    s = []
    # get the clip duration by dividing number of frames by the number of frames per second
    clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)
    # use np.arange() to make floating-point steps
    for i in np.arange(0, clip_duration, 1 / saving_fps):
        s.append(i)
    return s


def multi_class_image_classification(video_file):
    filename, _ = os.path.splitext(video_file)
    # make a folder by the name of the video file
    ctl = ConnectS3()
    resource = ctl.create_connection()
    ctl.download_from_s3(
        bucket_name=VISIONPLUS_DEV,
        filename_with_path=TF_LITE_MODEL_LOCAL_PATH,
        key=TFLITE_MODEL_PATH,
        resource=resource)
    interpreter = lite.Interpreter(model_path=TF_LITE_MODEL_LOCAL_PATH)
    interpreter.allocate_tensors()
    input_tensor_index = interpreter.get_input_details()[0]["index"]
    output = interpreter.tensor(interpreter.get_output_details()[0]["index"])
    if not os.path.isdir(filename):
        os.mkdir(filename)
    # read the video file
    cap = cv2.VideoCapture(video_file)
    # get the FPS of the video
    fps = cap.get(cv2.CAP_PROP_FPS)
    # if the SAVING_FRAMES_PER_SECOND is above video FPS, then set it to FPS (as maximum)
    saving_frames_per_second = min(fps, SAVING_FRAMES_PER_SECOND)
    # get the list of duration spots to save
    saving_frames_durations = get_saving_frames(cap, saving_frames_per_second)
    # start the loop
    count = 0
    while True:
        is_read, frame = cap.read()
        if not is_read:
            # break out of the loop if there are no frames to read
            break
        # get the duration by dividing the frame count by the FPS
        frame_duration = count / fps
        try:
            # get the earliest duration to save
            closest_duration = saving_frames_durations[0]
        except IndexError:
            # the list is empty, all duration frames were saved
            break
        if frame_duration >= closest_duration:
            # if closest duration is less than or equals the frame duration,
            # then save the frame
            frame = cv2.resize(frame, (227, 227))
            img_array = img_to_array(frame)
            img_array = expand_dims(img_array, 0)
            interpreter.set_tensor(input_tensor_index, img_array)
            interpreter.invoke()
            class_label = np.argmax(output()[0])
            if class_label == 5:
                frame_duration_formatted = format_timedelta(timedelta(seconds=frame_duration))
                cv2.imwrite(os.path.join(filename, f"frame{frame_duration_formatted}.jpg"), frame)

            # drop the duration spot from the list, since this duration spot is already saved
            try:
                saving_frames_durations.pop(0)
            except IndexError:
                pass
        # increment the frame count
        count += 1




